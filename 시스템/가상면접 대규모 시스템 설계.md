## 1장 사용자 수에 따른 규모 확장성
- 비관계형 데이터 베이스가 적합할 수 있는 상항
	- 아주 낮은 응답 지연시간 요구
	- 데이터가 비정형데이터
	- 데이터를 직렬화나 역직렬화만 할 수 있으면 됨
	- 아주 많은 양의 데이터를 저장할 필요가 있음

- 스케일 업
	- 트래픽의 양이 적을 때 좋은 선택
	- CPU나 메모리를 무한대로 증설할 방법이 없다.
	- 장애 대응이 어렵다. (자동복구나 다중화 방안이 없다.)
	-> 대규모 애플리케이션에서는 스케일 아웃이 적절하다.

- 로드밸런서
	- 트래픽 부하를 고르게 분산하는 역할

- 데이터베이스 다중화
	- 더 나은 성능
		- write -> master,  read -> slave 로 분산하여 병렬 처리한다.
	- 안정성
		- 데이터베이스 서버 일부가 파괴되어도 보존된다.
	- 가용성
		- 장애가 발생해도 다른 데이터베이스 서버를 연결하여 서비스를 지속할 수 있다.
 - [?] master 가 다운된 경우 : slave가 최신이 아닐 수 있다. 이때 어떻게 대처해야하는가?
	 - [ ] multi-masters, circular replication 도입

- CDN (콘텐츠 전송 네트워크)
	- 지리적으로 분산된 서버를 연결한 네트워크
	- 웹 컨텐츠의 복사본을 위치하여 웹 성능을 높인다.
	- 헤더에 캐시 시간(TTL) 이 들어있다.
	- third-party providers에 의해 운영되어 비용이 발생한다.
	- 만료시간을 적절하게 설정해야한다.
	- CDN 장애에 대처 - CDN이 응답하지 않을 경우 원본 서버에 요청하도록 클라이언트 구성.
	- 콘텐츠 무효화 방법 - CDN API 사용, 버저닝

- 캐시
	- 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어나는 경우 사용
	- 영속적으로 보관할 필요가 없는 데이터를 둔다.
	- 캐시 만료 정책을 정해야한다.
	- [?] 원본과의 일관성을 어떻게 유지할 것인가?
		- [ ] Scaling Memcache at Facebook
	- 캐시 서버가 한대일 경우 SPOF가 된다. 캐시 서버를 분산시켜야한다.
	- 캐시 메모리가 너무 작으면 데이터가 캐시에서 밀려나 성능이 떨어진다. 과할당하는 것이 좋다.
	- 데이터 방출 정책 : 캐시가 차면 LRU, LFU, FIFO 정책을 적용.

- 무상태 웹 계층
	- 서버가 세선 상태를 갖는 경우 서버가 여러대일 때 인증에 실패한다.
	- 로드밸런서가 고정 세션을 관리할 경우 부담이 된다.
	- 공유 저장소 (shared storage) 를 사용하여 웹 서버와 상태를 분리한다.
		- Redis, 관계형, NoSQL 등

- 다중 데이터 센터
	- 트래픽 우회 방안 강구 (GeoDNS는 가장 가까운 데이터 센터로 보낸다.)
	- 데이터를 여러 데이터 센터에 걸쳐 다중화시킨다.
	- 여러 위치에서 테스트를 해보고 배포하기.
	- -> 큰 규모로 확장하기 위해서는 시스템의 컴포넌트를 분리하여 독립적으로 확장가능해야한다.
	- -> 메시지 큐 사용

- 메시지 큐
	- 메시지의 무손실, 비동기 통신을 지원하는 컴포턴트
	- 메시지의 버퍼 역할을한다.
	- 서비스, 서버 간의 결합이 느슨해지고 규모 확장성이 보장된다.

- 샤딩
	- 수평적 확장
	- 데이터가 균등하지 못하거나 많아지는 경우 데이터를 재 샤딩해야하는 문제가 있다.
	- 유명인사 문제 : 특정 샤드에 부하가 몰릴 수 있다.
	- 여러 샤드 서버로 쪼개면 조인하기 힘들어진다.

## 2장 개략적인 규모 추정
- 2의 제곱수

|         |                    |                  |     |
| ------- | ------------------ | ---------------- | --- |
| 2의 x 제곱 | 근사치                | 이름               | 축약형 |
| 10      | 1천(thousand)       | 1킬로바이트(Kilobyte) | 1KB |
| 20      | 1백만(million)       | 1메가바이트(Megabyte) | 1MB |
| 30      | 109(billion)       | 1기가바이트(Gigabyte) | 1GB |
| 40      | 1조(trillion)       | 1테라바이트(Terabyte) | 1TB |
| 50      | 1000조(quadrillion) | 1페타바이트(Petabyte) | 1PB |
- 응답 시간 지연

|                                    |                       |
| ---------------------------------- | --------------------- |
| 연산명                                | 시간                    |
| L1 캐시 참조                           | 0.5ns                 |
| 분기 예측 오류(branch mispredict)        | 5ns                   |
| L2 캐시 참조                           | 7ns                   |
| 뮤텍스(mutex) 락/언락                    | 100ns                 |
| 주 메모리 참조                           | 100ns                 |
| Zippy로 1 KB 압축                     | 10,000ns = 10us       |
| 1Gbps 네트워크로 2 KB 전송                | 20,000ns = 20us       |
| 메모리에서 1 MB 순차적으로 read              | 250,000ns = 250us     |
| 같은 데이터 센터 내에서의 메시지 왕복 지연시간         | 500,000ns = 500us     |
| 디스크 탐색(seek)                       | 10,000,000ns = 10ms   |
| 네트워크에서 1 MB 순차적으로 read             | 10,000,000ns = 10ms   |
| 디스크에서 1 MB 순차적으로 read              | 30,000,000ns = 30ms   |
| 한 패킷의 CA(캘리포니아)로부터 네덜란드까지의 왕복 지연시간 | 150,000,000ns = 150ms |
- QPS : Query Per Second

## 3장 효과적인 면접을 위한 4단계 접근법
- 효과적인 면접을 위한 4단계 접근법
	- 1. 문제 이해 및 설계 범위 확정
		- 바로 답을 내지 말고 깊이 생각하고 요구사항, 가정을 분명히 하기
		- 옳바른 질문하기
	- 2. 개략적인 설계안 제시 및 동의 구하기
		- 핵심 다이어그램 그리기
		- 제약사항 만족여부 파악하기
	- 3. 상세 설계
		- 전반적으로 달성해야할 목표와 기능 범위 확인
		- 상세 설계에서 집중해야 할 영역 확인
		- 컴포넌트 사이의 우선순위 정하기
	- 4. 마무리
		- 비판적 사고하기
		- 요약하기
		- 오류 발생 상황 따져보기
		- 운영 이슈 논의하기
		- 확장성 고려하기
		- 세부 개선사항 제안하기
## 4장 처리율 제한 장치의 설계
- 처리율 제한 장치
	- 비용절감
	- 서버 과부하 막기
	- Dos 공격에 의한 자원 고갈 방지
- 1. 문제 이해 및 설계 범위 확정
	- 분산형 처리율 제한
	- 예외 처리
	- 높은 결함 감내성
- 2. 개략적 설계안 제시 및 동의 구하기
	- 위치 : 클라이언트 vs 서버 - 클라이언트 요청을 변조가 쉽다.
	- 서버에서 위치 : API 서버 vs API 게이트 웨이
		- 프로그래밍 언어가 서버 측 구현을 지원하기 충분한가?
		- 처리율 제한 알고리즘 선택할 것인가?
		- 사용자 인증이나 IP 허용목록관리를 위해 API 게이트웨이가 있는가?
		- API 게이트웨이를 만들 인력이 충분한가?
	- 처리율 제한 알고리즘
		- 토큰 버킷
			- 토큰을 일정시간마다 공급하고 요청마다 조진하는 형태
			- 토큰 공급률을 제한하고 버킷으로 통제한다.
			- 장점
				- 구현이 쉽다.
				- 메모리가 효율적이다.
				- 트래픽 처리 가능하다.
			- 단점
				- 버킷 크기, 토큰 공급률 2개의 인자를 가지고 있어 튜닝하기 까다롭다.
		- 누출 버킷
			- 큐에 쌓아두고 큐가 가득차면 버리는 방식
			- 요청 처리율이 고정되어있다.
		- 고정 윈도 카운터
			- 타임라인마다 윈도를 나누고 윈도마다 카운터를 붙인다.
			- 카운터가 임계치에 도달하면 새 윈도가 열릴 때까지 버린다.
			- 윈도 경계 부근해서 트래픽이 몰리는 경우 한도보다 많은 양의 요청을 처리하게된다.
		- 이동 윈도 로그
			- 로그의 크기가 허용치보다 작으면 시스템에 전달한다.
			- 만료된 타임스탬프는 제거한다.
			- 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.
			- 거부된 요청의 타임스탬프도 보관하기 때문에 다량의 메모리를 사용한다.
		- 이동 윈도 카운터
- 3. 상세 설계
	- 처리율 제한 규칙은 디스크에 보관
	- 클라이언트 요청이 미들웨어에 도달
	- 미들웨어가 제한 규칙가져오기, 카운터 및 타임스탬프 레디스 캐시에서 가져오기
	- 분산 환경에서 처리율 제한 장치 구현
		- 경쟁 조건
			- 락으로 해결가능 하지만 성능을 떨어뜨린다.
			- [?] 해결방안 : 루아 스크립트, 정렬 집합(레디스 자료구조)
		- 동기화 이슈
			- 고정 세션
				- 규모 확장성이 없다.
				- 유연하지 않다.
			- 레디스와 같은 중앙 집중형 데이터 저장소 사용.
		- 성능 최적화
			-  여러 데이터센터를 지원하면 지연시간 문제
			- 제한 장치 간 데이터 동기화 일관성 모델
- 4. 마무리
	-  경성 or 연성 처리율 제한
		- 잠시 동안 임계치를 넘을 수 있냐 없냐
	- 댜앙한 계층에서 처리율 제한
		- Iptables를 사용하여 IP주소에 처리율 제한 가능하다.
	- 회피방법
		- 클라이언트가 캐시를 사용하여 API 호출 횟수를 줄인다.

## 5장 안정 해시 설계
- N개의 캐시 서버가 있는 경우 부하를 균등하게 나누는 방법 - 해시 함수
- 서버가 장애가 났을 경우
	- 키 재분배가 이루어 진다.
	- 이 과정에서 대규모 캐시 미스가 발생한다.
- 안정 해시
	- 해시 공간과 해시 링을 생성하여 시계방향으로 돌며 key를 찾는다.
	- 파티션을 균등하게 유지하기 불가능하다.
	- 키의 균등 분포를 달성하기 어렵다.
	- 서버의 추가, 삭제 시 재배치 키의 수를 최소화한다.
	- 핫스팟 키 문제를 줄인다.
	- 수평적 규모 확장성을 달성하기 쉽다.

## 6장 키-값 저장소 설계
- 단일 서버 키-값 저장소
	- 모든 데이터를 메모리에 두는 것이 불가능할 수 있다.
-> 데이터 압축, 자주 쓰이는 데이터만 메모리, 나머지는 디스크

- 분산 키-값 저장소
	- CAP 정리
		- 데이터 일관성, 가용성, 파티션 감내 3가지를 모두 만족하는 분산 시스템을 설계하는 것은 불가능하다.
		- 데이터 일관성 : 노드에 상관없이 같은 데이터
		- 가용성 : 노드에 장애가 발생해도 항상 응답을 받는다.
		- 파티션 감내 : 두 노드 사이에 통신 장애가 발생해도 계속 동작
			- 네트워크 장애는 피할 수 없어 파티션 문제를 감내할 수 있게 설계되어야한다.
	- 금융권이라면 데이터 일관성을 양보할 수 없다.(CP 시스템)
		- 대신 가용성이 깨진다.
- 시스템 컴포넌트
	- 데이터 파티션
		- 데이터 고르게 분산
		- 데이터 이동 최소화
			-> 해시 링으로 배치
			-> Automatic scaling
			-> 서버 용량에 맞게 가상 노드 수 조정
	- 데이터 다중화
		- N개의 서버에 사본을 보관한다.
	- 데이터 일관성
		- N = 사본 개수, W = 쓰기 연산 정족수, R = 읽기 연산 정족수
		- 일관성 모델
			- 강한 일관성 : 모든 읽기 연산은 가장 최근 갱싱된 결과 반환
			- 약한 일관성 : 가장 최근 갱신된 결과를 반환하지 못할 수 있다.
			- 최종 일관성 : 결국에는 반영된다.
		-> 데이터 버저닝 : 데이터가 변경될 때마다 새로운 버전을 만든다.
	- 장애 감지
		- 모든 노드 사이에 연결을 구축하여 장애 감지
			-> 서버가 많으면 비효율적이다.
		- 가십 프로토콜
			- 주기적으로 자신의 박동 카운터를 증가시킨다.
			- 지정된 시간 동안 박동 카운터가 갱신되지 않으면 장애로 간주한다.
	- 영구 장애 처리

## 7장 분산 시스템을 위한 유일 ID 생성기 설계
- 다중 마스터 복제
	- ID를 데이터베이스 서버 수 만큼씩 증가시킨다.
		- 규모를 늘리기 어렵다.
		- 시간 흐름에 맞추어 커지는 것을 보장할 수 없다.
		- 서버 추가, 삭제시에 제대로 동작하게 만들기 어렵다.
- UUID
	- 장점
		- 동기화 이슈가 없다.
		- 규모 확장이 쉽다.
	- 단점
		- ID가 128비트로 길다.
		- 시간 순 정렬이 안된다.
		- 숫자가 아닌 값도 포함된다.
- 티켓 서버
	- 분산 기본키를 만들어내는 별도의 서버를 둔다.
		- 티켓 서버가 SPOF 이다.
		- 티켓 서버를 여러대 두면 데이터 동기화 문제가 발생한다.
- 트위터 스노플레이크 접근법
	- 독창적인 ID 생성 기법
		- 사인비트
		- 타임스탬프
		- 데이터센터 ID
		- 서버 ID
		- 일련번호
	- 서버의 시간이 다를 수 있다.
		- [!] NTP
	- 동시성이 낮고 수명이 긴 애플리케이션이라면 일련번호 절의 길이를 줄이고 타임스탬프 절의 길이를 늘리는 것이 효과적일 수 있다.
	- 고가용성 : ID 생성기는 필수 불가결 컴포넌트이르로 높은 가용성을 제공해야한다.

## 8장 URL 단축기 설계
- 데이터 모델
	- 해시 테이블에  <단축 URL, 원래 URL> 로 저장한다.
- 해시 함수
	- n =7이면 3.5조개를 만들 수 있다.
	- 해시 후 충돌 해소
		- 해시함수로 변환된 값이 DB에 존재하는지 질의하는 오버헤드가 크다.
		- [!] 블룸 필터로 특정 원소가 있는 검사하면 성능을 높일 수 있다.
- base-62 변환
	- 62진법으로 수를 표현한다.
	- 유일성 보장 ID 생성기가 필요
	- 충돌은 없다.
	- 1씩 증가한다면 보안상 문제가 될 수 있다.
- URL 리디렉션 상세 설계
	- 단축 URL 조회를 캐싱하여 성능을 높인다.

## 9장 웹 크롤러 설계
- 상세 설계
	- DFS vs BFS : 깊이 우선 탐색을 하면 같은 url에 많은 요청을 보내 ddos 가 될 수 있다.
	- 성능 최적화
		- 분산 크롤링 : 서버 다중화
		- DNS 캐싱 : DNS 결과를 받기 전까지 작업을 진행할 수 없다.
		- 지역성 : 서버를 지역별로 분산
		- 짧은 타임아웃 : 응답이 없으면 빠르게 넘어간다.
		- 안정성
			- 안정 해시 : 서버 부하 분산을 위해 서버 추가 삭제 쉬움
			- 크롤링 상태 및 수집 데이터 저장 : 지속 저장장치에 기록해둔다.
			- 예외 처리
			- 데이터 검증
		- 확장성
		- 문제 있는 콘텐츠 감지 및 회피
			- 중복 콘텐츠 해시, 체크섬으로 탐지
			- 거미 덫
				- 무한 루프에 빠지는 웹 페이지
				- 수작업으로 URL 목록을 찾아야한다.
			- 데이터 노이즈
## 10장 알림 시스템 설계
- 알림 유형별 지원 방안
	- 제 3자 사업자 제공 서비스가 필요하다.
		- iOS : APNS
		- 안드로이드 : FCM
		- SMS : Twilo, Nexmo
		- 이메일 : Sendgrid, Mailchimp
- 연락처 정보 수집 절차
	- 데이터 베이스에 이메일, 전화번호는 user Table, 단말 토큰은 device 테이블에 1:N으로 저장한다.
- 알림 전송 및 수신 절차
	- 알림 시스템 서버가 1대일 경우 SPOF이다, 성능 병목이 발생한다.
		- 데이터베이스, 캐시를 알림 시스템의 주 서버에서 분리한다.
		- 알림 서버 증설 및 Auto Scaling
		- 메시지 큐로 컴포넌트 사이의 강한 결합을 끊는다.
		- 알림 서버
			- 알림 전송 API
			- 알림 검증 : 이메일, 전화번호 검증
			- 데이터베이스 질의
			- 알림 메시지 큐 푸시
		- 캐시 : 사용자 정보, 단말 정보, 알림 탬플릿
		- 데이터베이스 : 사용자, 알림, 설정
		- 메시지 큐 : 의존성 분리, 대량 알림 버퍼, 알림 종류 별 메시지 큐(단일 장애 완화)
		- 작업 서버 : 메시지 큐에서 알림을 꺼내 제3자 서비스로 전달
- 안정성
	- 데이터 손실 방지 : 일림 데이터베이스 보관, 재시도 매커니즘
	- 알림 중복 전송 방지 : 이벤트 ID 검사 후 버리기
- 추가 고려사항
	- 알림 템플릿
	- 알림 설정 : 알림 비활성화 확안
	- 전송률 제한 : 알림 빈도 제한
	- 재시도 방법 : 전송 실패시 재시도
	- 푸시 알림과 보안 : Authenticated, Verified 된 클라이언트만 API 사용가능
	- 큐 모니터링 : 큐에 쌓인 알림의 개수가 너무 크면 이벤트 처리가 느리다.
	- 이벤트 추적 : 데이터 분석 서비스 

## 뉴스 피드 시스템 설계

		
