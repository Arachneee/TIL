## 1장 사용자 수에 따른 규모 확장성
- 비관계형 데이터 베이스가 적합할 수 있는 상항
	- 아주 낮은 응답 지연시간 요구
	- 데이터가 비정형데이터
	- 데이터를 직렬화나 역직렬화만 할 수 있으면 됨
	- 아주 많은 양의 데이터를 저장할 필요가 있음

- 스케일 업
	- 트래픽의 양이 적을 때 좋은 선택
	- CPU나 메모리를 무한대로 증설할 방법이 없다.
	- 장애 대응이 어렵다. (자동복구나 다중화 방안이 없다.)
	-> 대규모 애플리케이션에서는 스케일 아웃이 적절하다.

- 로드밸런서
	- 트래픽 부하를 고르게 분산하는 역할

- 데이터베이스 다중화
	- 더 나은 성능
		- write -> master,  read -> slave 로 분산하여 병렬 처리한다.
	- 안정성
		- 데이터베이스 서버 일부가 파괴되어도 보존된다.
	- 가용성
		- 장애가 발생해도 다른 데이터베이스 서버를 연결하여 서비스를 지속할 수 있다.
 - [?] master 가 다운된 경우 : slave가 최신이 아닐 수 있다. 이때 어떻게 대처해야하는가?
	 - [ ] multi-masters, circular replication 도입

- CDN (콘텐츠 전송 네트워크)
	- 지리적으로 분산된 서버를 연결한 네트워크
	- 웹 컨텐츠의 복사본을 위치하여 웹 성능을 높인다.
	- 헤더에 캐시 시간(TTL) 이 들어있다.
	- third-party providers에 의해 운영되어 비용이 발생한다.
	- 만료시간을 적절하게 설정해야한다.
	- CDN 장애에 대처 - CDN이 응답하지 않을 경우 원본 서버에 요청하도록 클라이언트 구성.
	- 콘텐츠 무효화 방법 - CDN API 사용, 버저닝

- 캐시
	- 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어나는 경우 사용
	- 영속적으로 보관할 필요가 없는 데이터를 둔다.
	- 캐시 만료 정책을 정해야한다.
	- [?] 원본과의 일관성을 어떻게 유지할 것인가?
		- [ ] Scaling Memcache at Facebook
	- 캐시 서버가 한대일 경우 SPOF가 된다. 캐시 서버를 분산시켜야한다.
	- 캐시 메모리가 너무 작으면 데이터가 캐시에서 밀려나 성능이 떨어진다. 과할당하는 것이 좋다.
	- 데이터 방출 정책 : 캐시가 차면 LRU, LFU, FIFO 정책을 적용.

- 무상태 웹 계층
	- 서버가 세선 상태를 갖는 경우 서버가 여러대일 때 인증에 실패한다.
	- 로드밸런서가 고정 세션을 관리할 경우 부담이 된다.
	- 공유 저장소 (shared storage) 를 사용하여 웹 서버와 상태를 분리한다.
		- Redis, 관계형, NoSQL 등

- 다중 데이터 센터
	- 트래픽 우회 방안 강구 (GeoDNS는 가장 가까운 데이터 센터로 보낸다.)
	- 데이터를 여러 데이터 센터에 걸쳐 다중화시킨다.
	- 여러 위치에서 테스트를 해보고 배포하기.
	- -> 큰 규모로 확장하기 위해서는 시스템의 컴포넌트를 분리하여 독립적으로 확장가능해야한다.
	- -> 메시지 큐 사용

- 메시지 큐
	- 메시지의 무손실, 비동기 통신을 지원하는 컴포턴트
	- 메시지의 버퍼 역할을한다.
	- 서비스, 서버 간의 결합이 느슨해지고 규모 확장성이 보장된다.

- 샤딩
	- 수평적 확장
	- 데이터가 균등하지 못하거나 많아지는 경우 데이터를 재 샤딩해야하는 문제가 있다.
	- 유명인사 문제 : 특정 샤드에 부하가 몰릴 수 있다.
	- 여러 샤드 서버로 쪼개면 조인하기 힘들어진다.

## 2장 개략적인 규모 추정
- 2의 제곱수

|         |                    |                  |     |
| ------- | ------------------ | ---------------- | --- |
| 2의 x 제곱 | 근사치                | 이름               | 축약형 |
| 10      | 1천(thousand)       | 1킬로바이트(Kilobyte) | 1KB |
| 20      | 1백만(million)       | 1메가바이트(Megabyte) | 1MB |
| 30      | 109(billion)       | 1기가바이트(Gigabyte) | 1GB |
| 40      | 1조(trillion)       | 1테라바이트(Terabyte) | 1TB |
| 50      | 1000조(quadrillion) | 1페타바이트(Petabyte) | 1PB |
- 응답 시간 지연

|                                    |                       |
| ---------------------------------- | --------------------- |
| 연산명                                | 시간                    |
| L1 캐시 참조                           | 0.5ns                 |
| 분기 예측 오류(branch mispredict)        | 5ns                   |
| L2 캐시 참조                           | 7ns                   |
| 뮤텍스(mutex) 락/언락                    | 100ns                 |
| 주 메모리 참조                           | 100ns                 |
| Zippy로 1 KB 압축                     | 10,000ns = 10us       |
| 1Gbps 네트워크로 2 KB 전송                | 20,000ns = 20us       |
| 메모리에서 1 MB 순차적으로 read              | 250,000ns = 250us     |
| 같은 데이터 센터 내에서의 메시지 왕복 지연시간         | 500,000ns = 500us     |
| 디스크 탐색(seek)                       | 10,000,000ns = 10ms   |
| 네트워크에서 1 MB 순차적으로 read             | 10,000,000ns = 10ms   |
| 디스크에서 1 MB 순차적으로 read              | 30,000,000ns = 30ms   |
| 한 패킷의 CA(캘리포니아)로부터 네덜란드까지의 왕복 지연시간 | 150,000,000ns = 150ms |
- QPS : Query Per Second

## 3장 효과적인 면접을 위한 4단계 접근법
- 효과적인 면접을 위한 4단계 접근법
	- 1. 문제 이해 및 설계 범위 확정
		- 바로 답을 내지 말고 깊이 생각하고 요구사항, 가정을 분명히 하기
		- 옳바른 질문하기
	- 2. 개략적인 설계안 제시 및 동의 구하기
		- 핵심 다이어그램 그리기
		- 제약사항 만족여부 파악하기
	- 3. 상세 설계
		- 전반적으로 달성해야할 목표와 기능 범위 확인
		- 상세 설계에서 집중해야 할 영역 확인
		- 컴포넌트 사이의 우선순위 정하기
	- 4. 마무리
		- 비판적 사고하기
		- 요약하기
		- 오류 발생 상황 따져보기
		- 운영 이슈 논의하기
		- 확장성 고려하기
		- 세부 개선사항 제안하기
## 4장 처리율 제한 장치의 설계
- 처리율 제한 장치
	- 비용절감
	- 서버 과부하 막기
	- Dos 공격에 의한 자원 고갈 방지
- 1. 문제 이해 및 설계 범위 확정
	- 분산형 처리율 제한
	- 예외 처리
	- 높은 결함 감내성
- 2. 개략적 설계안 제시 및 동의 구하기
	- 위치 : 클라이언트 vs 서버 - 클라이언트 요청을 변조가 쉽다.
	- 서버에서 위치 : API 서버 vs API 게이트 웨이
		- 프로그래밍 언어가 서버 측 구현을 지원하기 충분한가?
		- 처리율 제한 알고리즘 선택할 것인가?
		- 사용자 인증이나 IP 허용목록관리를 위해 API 게이트웨이가 있는가?
		- API 게이트웨이를 만들 인력이 충분한가?
	- 처리율 제한 알고리즘
		- 토큰 버킷
			- 토큰을 일정시간마다 공급하고 요청마다 조진하는 형태
			- 토큰 공급률을 제한하고 버킷으로 통제한다.
			- 장점
				- 구현이 쉽다.
				- 메모리가 효율적이다.
				- 트래픽 처리 가능하다.
			- 단점
				- 버킷 크기, 토큰 공급률 2개의 인자를 가지고 있어 튜닝하기 까다롭다.
		- 누출 버킷
			- 큐에 쌓아두고 큐가 가득차면 버리는 방식
			- 요청 처리율이 고정되어있다.
		- 고정 윈도 카운터
			- 타임라인마다 윈도를 나누고 윈도마다 카운터를 붙인다.
			- 카운터가 임계치에 도달하면 새 윈도가 열릴 때까지 버린다.
			- 윈도 경계 부근해서 트래픽이 몰리는 경우 한도보다 많은 양의 요청을 처리하게된다.
		- 이동 윈도 로그
			- 로그의 크기가 허용치보다 작으면 시스템에 전달한다.
			- 만료된 타임스탬프는 제거한다.
			- 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.
			- 거부된 요청의 타임스탬프도 보관하기 때문에 다량의 메모리를 사용한다.
		- 이동 윈도 카운터
- 3. 상세 설계
	- 처리율 제한 규칙은 디스크에 보관
	- 클라이언트 요청이 미들웨어에 도달
	- 미들웨어가 제한 규칙가져오기, 카운터 및 타임스탬프 레디스 캐시에서 가져오기
	- 분산 환경에서 처리율 제한 장치 구현
		- 경쟁 조건
			- 락으로 해결가능 하지만 성능을 떨어뜨린다.
			- [?] 해결방안 : 루아 스크립트, 정렬 집합(레디스 자료구조)
		- 동기화 이슈
			- 고정 세션
				- 규모 확장성이 없다.
				- 유연하지 않다.
			- 레디스와 같은 중앙 집중형 데이터 저장소 사용.
		- 성능 최적화
			-  여러 데이터센터를 지원하면 지연시간 문제
			- 제한 장치 간 데이터 동기화 일관성 모델
- 4. 마무리
	-  경성 or 연성 처리율 제한
		- 잠시 동안 임계치를 넘을 수 있냐 없냐
	- 댜앙한 계층에서 처리율 제한
		- Iptables를 사용하여 IP주소에 처리율 제한 가능하다.
	- 회피방법
		- 클라이언트가 캐시를 사용하여 API 호출 횟수를 줄인다.

## 5장 안정 해시 설계
- N개의 캐시 서버가 있는 경우 부하를 균등하게 나누는 방법 - 해시 함수
- 서버가 장애가 났을 경우
	- 키 재분배가 이루어 진다.
	- 이 과정에서 대규모 캐시 미스가 발생한다.
- 안정 해시
	- 해시 공간과 해시 링을 생성하여 시계방향으로 돌며 key를 찾는다.
	- 파티션을 균등하게 유지하기 불가능하다.
	- 키의 균등 분포를 달성하기 어렵다.
	- 서버의 추가, 삭제 시 재배치 키의 수를 최소화한다.
	- 핫스팟 키 문제를 줄인다.
	- 수평적 규모 확장성을 달성하기 쉽다.

## 6장 키-값 저장소 설계
- non-relational	